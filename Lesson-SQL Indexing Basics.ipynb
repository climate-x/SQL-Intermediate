{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson - SQL Indexing\n",
    "\n",
    "In this lesson, we'll explore how queries are executed in SQLite. After exploring this at a high level, we will explore how to create and use indexes for better performance. As our data gets larger and our queries more complex, it's important to be able to tweak the queries we write and optimize a database's schema to ensure that we're getting results back quickly.\n",
    "\n",
    "To explore database performance, we'll work with `factbook.db`, a SQLite database that contains information about each country in the world. We'll be working with the `facts` table in the database. Each row in facts represents a single country, and contains several columns, including:\n",
    "\n",
    "`name` -- the name of the country.\n",
    "`area` -- the total land and sea area of the country.\n",
    "`population` -- the population of the country.\n",
    "`birth_rate` -- the birth rate of the country.\n",
    "`created_at` -- the date the record was created.\n",
    "`updated_at` -- the date the record was updated.\n",
    "\n",
    "**Exercise - Setting up Environment**\n",
    "We will work with sqlite from python.\n",
    "- Write a query that returns the schema of the facts table and assign the resulting list of tuples to schema.\n",
    "- Use a for loop and a print statement to display each tuple in schema on a separate line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 'id', 'INTEGER', 1, None, 1)\n",
      "(1, 'code', 'varchar(255)', 1, None, 0)\n",
      "(2, 'name', 'varchar(255)', 1, None, 0)\n",
      "(3, 'area', 'integer', 0, None, 0)\n",
      "(4, 'area_land', 'integer', 0, None, 0)\n",
      "(5, 'area_water', 'integer', 0, None, 0)\n",
      "(6, 'population', 'integer', 0, None, 0)\n",
      "(7, 'population_growth', 'float', 0, None, 0)\n",
      "(8, 'birth_rate', 'float', 0, None, 0)\n",
      "(9, 'death_rate', 'float', 0, None, 0)\n",
      "(10, 'migration_rate', 'float', 0, None, 0)\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "conn=sqlite3.connect(\"factbook.db\")\n",
    "\n",
    "schema=conn.execute(\"pragma table_info(facts);\").fetchall() #we can directly run query without instantiating a cursor obect\n",
    "for s in schema:\n",
    "    print(s)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query Planner\n",
    "When we execute a SQL query, SQLite performs many steps before returning the results. First, it tokenizes and parses the query to look for any syntax errors. If there are any syntax errors, the query execution process halts and the error message is returned to you. If the parser was able to successfully parse the query, then SQLite moves on to the query planning and optimization phase.\n",
    "\n",
    "When working with a database that's stored on disk as a file, it's crucial to minimize the amount of disk reads necessary to avoid long running times. The **query optimizer** generates cost estimates for the various ways to access the underlying data, factoring in the schema of the tables and the operations the query requires.\n",
    "\n",
    "The **optimizer** quickly assesses the various ways to access the data and generates a best guess for the fastest query plan. This high level query plan is then converted into highly efficient, lower-level C code to interact with the database file on disk. We can observe the query plan to understand what SQLite is doing to return our results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `EXPLAIN` QUERY PLAN\n",
    "\n",
    "We can use the `EXPLAIN QUERY PLAN` statement before any query we're running to get a high level query plan that would be performed. If you write a SELECT statement and place the EXPLAIN QUERY PLAN statement before it:\n",
    "`EXPLAIN QUERY PLAN SELECT * FROM facts;`\n",
    "the results of the SELECT query won't be returned and instead the high level query plan will be:\n",
    "```\n",
    "[(0, 0, 0, 'SCAN TABLE facts')]\n",
    "\n",
    "```\n",
    "\n",
    "We'll focus on `'SCAN TABLE facts'`, the last value from the returned tuple. `SCAN TABLE` means that every row in the entire table (facts) had to be accessed to evaluate the query. Since the SELECT query we wrote returns all of the columns and rows in the facts table, the entire table had to be accessed to get the results we requested.\n",
    "\n",
    "  When running the query using the `sqlite3` library, we'll need to use the `fetchall()` method.\n",
    "  ```\n",
    "  query_plan = conn.execute(\"EXPLAIN QUERY PLAN SELECT * FROM facts;\").fetchall()\n",
    "  ```\n",
    "The query plan is represented as a tuple, which is the sqlite3 library's preferred way of representing results.\n",
    "\n",
    "**Exercise**\n",
    "- Return the query plan for the query that returns all columns and rows where area exceeds 40000. Assign the results to `query_plan_one`.\n",
    "\n",
    "- Return the query plan for the query that returns only the `area` column for all rows where area exceeds 40000. Assign the results to `query_plan_two`.\n",
    "\n",
    "- Return the query plan for the query that returns the row for the country Czech Republic. Assign the results to `query_plan_three`.\n",
    "\n",
    "- Use the print function to display each query plan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2, 0, 0, 'SCAN TABLE facts')]\n",
      "[(2, 0, 0, 'SCAN TABLE facts')]\n",
      "[(2, 0, 0, 'SCAN TABLE facts')]\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "conn=sqlite3.connect(\"factbook.db\")\n",
    "\n",
    "query_one=\"EXPLAIN QUERY PLAN SELECT * FROM facts WHERE area>40000;\"\n",
    "query_plan_one=conn.execute(query_one).fetchall()\n",
    "\n",
    "query_two=\"EXPLAIN QUERY PLAN SELECT area FROM facts WHERE area>40000;\"\n",
    "query_plan_two=conn.execute(query_two).fetchall()\n",
    "\n",
    "query_three=\"EXPLAIN QUERY PLAN SELECT * FROM facts WHERE name='Czech Republic';\"\n",
    "query_plan_three=conn.execute(query_three).fetchall()\n",
    "\n",
    "print(query_plan_one)\n",
    "print(query_plan_two)\n",
    "print(query_plan_three)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Representation\n",
    "all 3 query plans are exactly the same. The entire facts table had to be accessed to return the data we needed for all 3 queries. Even though all the queries asked for a subset of the facts table, SQLite still ends up scanning the entire table. This is because of the way SQLite represents data.\n",
    "\n",
    "For the facts table, we set the `id` column as the `primary key` and SQLite uses this column to order the records in the database file. Since the rows are ordered by `id`, SQLite can search for a specific row based on it's `id` value using binary search. Unless we provide specific `id` values in the `WHERE` statement in the query, SQLite can't take advantage of binary search and has to instead scan the entire table, row by row.\n",
    "\n",
    "To return the results for the first 2 queries, SQLite has to:\n",
    "\n",
    "- Access the first row in the table (lowest id value),\n",
    "- check if that row's value for area exceeds 40000 and store the row separately in a temporary collection if it is,\n",
    "move onto the next row,\n",
    "- check if that row's value for area exceeds 40000 and store the row separately in a temporary collection if it is,\n",
    "- repeat moving and checking each row for the rest of the table,\n",
    "- return the final collection of rows that meet the criteria.\n",
    "\n",
    "If we were instead interested in a row with a specific id value, like in the third query:\n",
    "`SELECT * FROM facts WHERE id=15;`\n",
    "\n",
    "SQLite can use binary search to quickly find the corresponding row at that id value. Instead of performing a full table scan, SQLite would:\n",
    "\n",
    "- use binary search to find the first row where the id value matches 15 in `O(log N)` time complexity and store this row in a temporary collection,\n",
    "- advance to the next row to look for any more rows with the same id values and add those rows to the temporary collection,\n",
    "- return the final collection of rows that matched.\n",
    "\n",
    "If we set the `id` column to be a `UNIQUE PRIMARY KEY` when we created the schema, SQLite would stop searching when it found the instances that matched the `id` value. It would avoid advancing to the next row(s) since no 2 rows could have the same id value. While we didn't enforce the `UNIQUE` constraint on the `id` column, all of the values currently in the column are in fact unique and SQLite will only have to advance one row to realize this since they're ordered."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Complexity\n",
    "\n",
    "Binary search on a table using the primary key would be `O(log N)` time complexity where `N` is the number of total rows in the table. On the other hand, a full table scan would would be `O(N)` time complexity since each row would have to be accessed. If we're working with a database containing millions of rows, binary search would be over a million times faster! \n",
    "\n",
    "**Exercise**\n",
    "Return the query plan for the query that selects the row at `id value 20` from the `facts` table.\n",
    "Assign the query plan to `query_plan_four` and display the query plan using the print function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2, 0, 0, 'SEARCH TABLE facts USING INTEGER PRIMARY KEY (rowid=?)')]\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "conn=sqlite3.connect(\"factbook.db\")\n",
    "\n",
    "query_four=\"EXPLAIN QUERy PLAN SELECT * FROM facts WHERE id=20;\"\n",
    "query_plan_four=conn.execute(query_four).fetchall()\n",
    "print(query_plan_four)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search and rowid\n",
    "\n",
    "Instead of using a full table scan:\n",
    "`[(0, 0, 0, 'SCAN TABLE facts')]`\n",
    "\n",
    "SQLite performed binary search on the `facts` table using the integer primary key:\n",
    "`[(0, 0, 0, 'SEARCH TABLE facts USING INTEGER PRIMARY KEY (rowid=?)')]`\n",
    "\n",
    "SQLite uses `rowid` to refer to the primary key of a table. The alias `rowid` will be displayed in the query plan, no matter what you name the primary key column for that table. Either `SCAN` or `SEARCH` will always appear at the start of the query explanation for SELECT queries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing\n",
    "\n",
    "SQLite can take advantage of speedy lookups when searching for a specific primary key. Unfortunately, we don't always have the primary keys for the rows we're interested in beforehand. When we're expressing our intent as a SQL query, we're often thinking in terms of row and column values. We need to find a way that allows us to benefit from the speed of primary key lookups without actually knowing the primary key in advance.\n",
    "\n",
    "To that end, we could create a separate table that's optimized for lookups by a different column from the facts table instead of by the id. We can make the column we want to query by the primary key, so we get the speed benefits, and embed the id value from the facts table corresponding to that row. We call this table an `index` and each row in the `index` contains:\n",
    "\n",
    "- the value we want to be able to search by, as the primary key,\n",
    "- an id value for the corresponding row in facts.\n",
    "\n",
    "If we wrote a `SELECT` query to look up the population of India from the facts table:\n",
    "`SELECT population FROM facts WHERE name = 'India';`\n",
    "\n",
    "SQLite would need to perform a full table scan on `facts` to find the specific row where the value for name was India. We can instead create an `index` that's ordered by name values (primary key) and where each row contains the corresponding row's `id` from the facts table. Here's what that index would look like:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating an Index\n",
    "\n",
    "Instead of creating a separate table and updating it ourselves, we can specify a column we want an index table for and `SQLite` will take care of the rest. `SQLite`, and most databases, make it easy for you to create indexes for tables on columns we plan to query often. To create an index we use the `CREATE INDEX` statement:\n",
    "`CREATE INDEX index_name ON table_name(column_name);`\n",
    "\n",
    "Each index we create needs a name (to replace index_name). Similar to when we add a table to a database, using the `IF NOT EXISTS` clause helps us avoid attempting to create an index that already exists. Doing so will cause SQLite to throw an error. To create an index for the `area` column called `area_idx`, we write the following query:\n",
    "```\n",
    "CREATE INDEX IF NOT EXISTS area_idx ON facts(area);\n",
    "```\n",
    "An empty array will be returned when we run the query. The main benefit of having `SQLite` handle the maintenance of indexes we create is that the indexes are used automatically when we execute a query whenever there will be any speed advantages. As our queries become more complex, letting SQLite decide how and when to use the indexes we create helps us be much more productive.\n",
    "\n",
    "If we create an index for the `area` column in the `facts` table, `SQLite` will use the index whenever we search for rows in facts using that column. Each row would only contain the `area` value and the corresponding row's `id` value. The index would be ordered by the area values for quick lookups.\n",
    "\n",
    "All three of the following queries would take advantage of the area_idx index:\n",
    "```\n",
    "SELECT * FROM facts WHERE area = 10000;\n",
    "SELECT * FROM facts WHERE area > 10000;\n",
    "SELECT * FROM facts WHERE area < 10000;\n",
    "```\n",
    "Since the area_idx index would be ordered by the area values, SQLite would:\n",
    "\n",
    "- search for the first instance in the index where area equaled 10000 and store the `id` value in a temporary collection.\n",
    "- it would then advance to the next row in the index to check if the `WHERE` condition was still met.\n",
    "- if not, then the temporary collection would be returned and the process completes.\n",
    "- if so, then SQLite would add that `id` value to the collection and check the next row.\n",
    "- when SQLite finds a value for area that doesn't match the `WHERE` condition,\n",
    " - it will look up and return the rows in facts using the id values stored in the temporary collection.\n",
    " - each of these lookups will be `O(log N)` time complexity and while this could add up, it will still be faster than a full table scan.\n",
    " \n",
    "This process allows us to just write one query instead of 2 and have `SQLite` maintain and interact with the index. A table can have many indexes, and most tables in production environments usually do have many indexes. **Every time we add or delete a row to the table, all of the indexes will be updated**. If we edit the values in a row, SQLite will figure out which indexes are affected by the changes and update those indexes.\n",
    "\n",
    "While creating indexes gives us tremendous speed benefits, they come at the cost of space. Each index needs to be stored in the database file. In addition, adding, editing, and deleting rows takes longer since each of the affected indexes need to be updated. Since indexes can be created after a table is created, it's recommended to only create an index while querying on a specific column frequently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**\n",
    "\n",
    "- Return the query plan for the query that returns all values in the rows in `facts` where the population exceeds 10000. Assign the resulting query plan to `query_plan_six` and display using the print function.\n",
    "- Create an index for the population column in the facts table named pop_idx.\n",
    "- Return the query plan for the query that returns all values in the rows in facts where the population exceeds 10000. Assign the resulting query plan to query_plan_seven and display using the print function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2, 0, 0, 'SCAN TABLE facts')]\n",
      "[(3, 0, 0, 'SEARCH TABLE facts USING INDEX pop_idx (population>?)')]\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "conn=sqlite3.connect(\"factbook.db\")\n",
    "\n",
    "query_six=\"EXPLAIN QUERy PLAN SELECT * FROM facts WHERE population>10000;\"\n",
    "query_plan_six=conn.execute(query_six).fetchall()\n",
    "\n",
    "conn.execute(\"CREATE INDEX IF NOT EXISTS pop_idx ON facts(population);\")\n",
    "\n",
    "query_seven=\"EXPLAIN QUERy PLAN SELECT * FROM facts WHERE population>10000;\"\n",
    "query_plan_seven=conn.execute(query_seven).fetchall()\n",
    "\n",
    "print(query_plan_six)\n",
    "print(query_plan_seven)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of ending in `USING INDEX pop_idx (population)`, the query plan ended in `USING INDEX pop_idx (population>?)`. This is to indicate the granularity of the lookup that SQLite had to do for that index."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
